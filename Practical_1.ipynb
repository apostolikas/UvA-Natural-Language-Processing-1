{"cells":[{"cell_type":"markdown","metadata":{"id":"1-aRiOgl4nHg"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","------\n","**You cannot save any changes you make to this file, so please make sure to save it on your Google Colab drive or download it as a .ipynb file.**\n","\n","------\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"lIZrAUx57vsM"},"source":["Practical 1: Sentiment Detection in Movie Reviews\n","========================================\n","\n"]},{"cell_type":"markdown","metadata":{"id":"J4kXPMhyngZW"},"source":["This practical concerns detecting sentiment in movie reviews. This is a typical NLP classification task.\n","In [this file](https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json) (80MB) you will find 1000 positive and 1000 negative **movie reviews**.\n","Each review is a **document** and consists of one or more sentences.\n","\n","To prepare yourself for this practical, you should\n","have a look at a few of these texts to understand the difficulties of\n","the task: how might one go about classifying the texts? You will write\n","code that decides whether a movie review conveys positive or\n","negative sentiment.\n","\n","Please make sure you have read the following paper:\n","\n",">   Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan\n","(2002). \n","[Thumbs up? Sentiment Classification using Machine Learning\n","Techniques](https://dl.acm.org/citation.cfm?id=1118704). EMNLP.\n","\n","Bo Pang et al. introduced the movie review sentiment\n","classification task, and the above paper was one of the first papers on\n","the topic. The first version of your sentiment classifier will do\n","something similar to Pang et al.'s system. If you have questions about it,\n","you should resolve you doubts as soon as possible with your TA.\n"]},{"cell_type":"markdown","metadata":{"id":"cb7errgRASzZ"},"source":["**Advice**\n","\n","Please read through the entire practical and familiarise\n","yourself with all requirements before you start coding or otherwise\n","solving the tasks. Writing clean and concise code can make the difference\n","between solving the assignment in a matter of hours, and taking days to\n","run all experiments.\n","\n","## Environment\n","\n","All code should be written in **Python 3**. \n","This is the default in Google Colab."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1668525788617,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"SaZnxptMJiD7","outputId":"fbae8863-0866-4899-b52b-28e0ce98c5cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.7.15\n"]}],"source":["!python --version"]},{"cell_type":"markdown","metadata":{"id":"BYZyIF7lJnGn"},"source":["If you want to run code on your own computer, then download this notebook through `File -> Download .ipynb`.\n","The easiest way to\n","install Python is through downloading\n","[Anaconda](https://www.anaconda.com/download). \n","After installation, you can start the notebook by typing `jupyter notebook filename.ipynb`.\n","You can also use an IDE\n","such as [PyCharm](https://www.jetbrains.com/pycharm/download/) to make\n","coding and debugging easier. It is good practice to create a [virtual\n","environment](https://docs.python.org/3/tutorial/venv.html) for this\n","project, so that any Python packages don’t interfere with other\n","projects. \n"," \n","\n","**Learning Python 3**\n","\n","If you are new to Python 3, you may want to check out a few of these resources:\n","- https://learnxinyminutes.com/docs/python3/\n","- https://www.learnpython.org/\n","- https://docs.python.org/3/tutorial/"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1442,"status":"ok","timestamp":1668525790354,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"hok-BFu9lGoK"},"outputs":[],"source":["import math\n","import os\n","import sys\n","from subprocess import call\n","from nltk import FreqDist\n","from nltk.util import ngrams\n","from nltk.stem.porter import PorterStemmer\n","import sklearn as sk\n","from google.colab import drive\n","import pickle\n","import json\n","from collections import Counter\n","import requests\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"bXWyGHwE-ieQ"},"source":["## Loading the data\n","\n","**Download the sentiment lexicon and the movie reviews dataset.**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1668525793263,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"lm-rakqtlMOT","outputId":"4b5aca79-8a1e-4961-9d07-ebfd9e42a096"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-11-15 15:23:11--  https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n","Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 662577 (647K) [text/plain]\n","Saving to: ‘sent_lexicon’\n","\n","\rsent_lexicon          0%[                    ]       0  --.-KB/s               \rsent_lexicon        100%[===================>] 647.05K  --.-KB/s    in 0.02s   \n","\n","2022-11-15 15:23:12 (39.7 MB/s) - ‘sent_lexicon’ saved [662577/662577]\n","\n","--2022-11-15 15:23:12--  https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json\n","Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 83503869 (80M) [text/plain]\n","Saving to: ‘reviews.json’\n","\n","reviews.json        100%[===================>]  79.63M   312MB/s    in 0.3s    \n","\n","2022-11-15 15:23:12 (312 MB/s) - ‘reviews.json’ saved [83503869/83503869]\n","\n"]}],"source":["# download sentiment lexicon\n","!wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n","# download review data\n","!wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"]},{"cell_type":"markdown","metadata":{"id":"AkPwuHp5LSuQ"},"source":["**Load the movie reviews.**\n","\n","Each word in a review comes with its part-of-speech tag. For documentation on POS-tags, see https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3844,"status":"ok","timestamp":1668525820876,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"careEKj-mRpl","outputId":"fbaa3785-1220-4c2c-a870-3c38100f9b28"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of reviews: 2000 \n","\n","0 NEG 29\n","Two/CD teen/JJ couples/NNS go/VBP to/TO a/DT church/NN party/NN ,/, drink/NN and/CC then/RB drive/NN ./.\n","1 NEG 11\n","Damn/JJ that/IN Y2K/CD bug/NN ./.\n","2 NEG 24\n","It/PRP is/VBZ movies/NNS like/IN these/DT that/WDT make/VBP a/DT jaded/JJ movie/NN viewer/NN thankful/JJ for/IN the/DT invention/NN of/IN the/DT Timex/NNP IndiGlo/NNP watch/NN ./.\n","3 NEG 19\n","QUEST/NN FOR/IN CAMELOT/NNP ``/`` Quest/NNP for/IN Camelot/NNP ''/'' is/VBZ Warner/NNP Bros./NNP '/POS first/JJ feature-length/JJ ,/, fully-animated/JJ attempt/NN to/TO steal/VB clout/NN from/IN Disney/NNP 's/POS cartoon/NN empire/NN ,/, but/CC the/DT mouse/NN has/VBZ no/DT reason/NN to/TO be/VB worried/VBN ./.\n","4 NEG 38\n","Synopsis/NNPS :/: A/DT mentally/RB unstable/JJ man/NN undergoing/VBG psychotherapy/NN saves/VBZ a/DT boy/NN from/IN a/DT potentially/RB fatal/JJ accident/NN and/CC then/RB falls/VBZ in/IN love/NN with/IN the/DT boy/NN 's/POS mother/NN ,/, a/DT fledgling/NN restauranteur/NN ./.\n","\n","Number of word types: 47743\n","Number of word tokens: 1512359\n","\n","Most common tokens:\n","         , :    77842\n","       the :    75948\n","         . :    59027\n","         a :    37583\n","       and :    35235\n","        of :    33864\n","        to :    31601\n","        is :    25972\n","        in :    21563\n","        's :    18043\n","        it :    15904\n","      that :    15820\n","     -rrb- :    11768\n","     -lrb- :    11670\n","        as :    11312\n","      with :    10739\n","       for :     9816\n","       his :     9542\n","      this :     9497\n","      film :     9404\n"]}],"source":["# file structure:\n","# [\n","#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n","#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n","#   ..\n","# ]\n","# where `content` is a list of sentences, \n","# with a sentence being a list of (token, pos_tag) pairs.\n","\n","\n","with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n","  reviews = json.load(f)\n","  \n","print(\"Total number of reviews:\", len(reviews), '\\n')\n","\n","def print_sentence_with_pos(s):\n","  print(\" \".join(\"%s/%s\" % (token, pos_tag) for token, pos_tag in s))\n","\n","for i, r in enumerate(reviews):\n","  print(r[\"cv\"], r[\"sentiment\"], len(r[\"content\"]))  # cv, sentiment, num sents\n","  print_sentence_with_pos(r[\"content\"][0])\n","  if i == 4: \n","    break\n","    \n","c = Counter()\n","for review in reviews:\n","  for sentence in review[\"content\"]:\n","    for token, pos_tag in sentence:\n","      c[token.lower()] += 1\n","      \n","print(\"\\nNumber of word types:\", len(c))\n","print(\"Number of word tokens:\", sum(c.values()))\n","\n","print(\"\\nMost common tokens:\")\n","for token, count in c.most_common(20):\n","  print(\"%10s : %8d\" % (token, count))\n","  "]},{"cell_type":"markdown","metadata":{"id":"E6PWaEoh8B34"},"source":["#(1) Lexicon-based approach (3.5pts)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JsTSMb6ma4E8"},"source":["A traditional approach to classify documents according to their sentiment is the lexicon-based approach. To implement this approach, you need a **sentiment lexicon**, i.e., a list of words annotated with a sentiment label (e.g., positive and negative, or a score from 0 to 5).\n","\n","In this practical, you will use the sentiment\n","lexicon released by Wilson et al. (2005).\n","\n","> Theresa Wilson, Janyce Wiebe, and Paul Hoffmann\n","(2005). [Recognizing Contextual Polarity in Phrase-Level Sentiment\n","Analysis](http://www.aclweb.org/anthology/H/H05/H05-1044.pdf). HLT-EMNLP.\n","\n","Pay attention to all the information available in the sentiment lexicon. The field *word1* contains the lemma, *priorpolarity* contains the sentiment label (positive, negative, both, or neutral), *type* gives you the magnitude of the word's sentiment (strong or weak), and *pos1* gives you the part-of-speech tag of the lemma. Some lemmas can have multiple part-of-speech tags and thus multiple entries in the lexicon. The path of the lexicon file is `\"sent_lexicon\"`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668517423433,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"Ogq0Eq2hQglh","outputId":"f6dc7fc8-49eb-47e9-8f01-ac0ba6a9b522"},"outputs":[{"name":"stdout","output_type":"stream","text":["type=weaksubj len=1 word1=abandoned pos1=adj stemmed1=n priorpolarity=negative\n","type=weaksubj len=1 word1=abandonment pos1=noun stemmed1=n priorpolarity=negative\n","type=weaksubj len=1 word1=abandon pos1=verb stemmed1=y priorpolarity=negative\n","type=strongsubj len=1 word1=abase pos1=verb stemmed1=y priorpolarity=negative\n","type=strongsubj len=1 word1=abasement pos1=anypos stemmed1=y priorpolarity=negative\n","{'cv': 999, 'sentiment': 'NEG', 'content': [[['Two', 'CD'], ['party', 'NN'], ['guys', 'NNS'], ['bob', 'VBP'], ['their', 'PRP$'], ['heads', 'NNS'], ['to', 'TO'], ['Haddaway', 'NNP'], [\"'s\", 'POS'], ['dance', 'NN'], ['hit', 'VBD'], ['``', '``'], ['What', 'WP'], ['Is', 'VBZ'], ['Love', 'NNP'], ['?', '.'], [\"''\", \"''\"]], [['while', 'IN'], ['getting', 'VBG'], ['themselves', 'PRP'], ['into', 'IN'], ['trouble', 'NN'], ['in', 'IN'], ['nightclub', 'NN'], ['after', 'IN'], ['nightclub', 'NN'], ['.', '.']], [['It', 'PRP'], [\"'s\", 'VBZ'], ['barely', 'RB'], ['enough', 'JJ'], ['to', 'TO'], ['sustain', 'VB'], ['a', 'DT'], ['three-minute', 'JJ'], ['_', 'CD'], ['Saturday_Night_Live', 'JJ'], ['_', 'NN'], ['skit', 'NN'], [',', ','], ['but', 'CC'], ['_', 'CD'], ['SNL', 'NN'], ['_', 'NN'], ['producer', 'NN'], ['Lorne', 'NNP'], ['Michaels', 'NNP'], [',', ','], ['_', 'CD'], ['Clueless', 'JJ'], ['_', 'NN'], ['creator', 'NN'], ['Amy', 'NNP'], ['Heckerling', 'NNP'], [',', ','], ['and', 'CC'], ['Paramount', 'NNP'], ['Pictures', 'NNP'], ['saw', 'VBD'], ['something', 'NN'], ['in', 'IN'], ['the', 'DT'], ['late', 'JJ'], ['night', 'NN'], ['television', 'NN'], ['institution', 'NN'], [\"'s\", 'POS'], ['recurring', 'VBG'], ['``', '``'], ['Roxbury', 'NNP'], ['Guys', 'NNP'], [\"''\", \"''\"], ['sketch', 'NN'], ['that', 'WDT'], ['would', 'MD'], ['presumably', 'RB'], ['make', 'VB'], ['a', 'DT'], ['good', 'JJ'], ['feature', 'NN'], ['.', '.']], [['Emphasis', 'NN'], ['on', 'IN'], ['the', 'DT'], ['word', 'NN'], ['``', '``'], ['presumably', 'RB'], ['.', '.'], [\"''\", \"''\"]], [['_', 'SYM'], ['A_Night_at_the_Roxbury', 'NN'], ['_', 'NN'], ['takes', 'VBZ'], ['an', 'DT'], ['already-thin', 'JJ'], ['concept', 'NN'], ['and', 'CC'], ['tediously', 'RB'], ['stretches', 'VBZ'], ['it', 'PRP'], ['far', 'RB'], ['beyond', 'IN'], ['the', 'DT'], ['breaking', 'NN'], ['point', 'NN'], ['--', ':'], ['and', 'CC'], ['that', 'IN'], ['of', 'IN'], ['viewers', 'NNS'], [\"'\", 'POS'], ['patience', 'NN'], ['levels', 'NNS'], ['.', '.']], [['The', 'DT'], ['first', 'JJ'], ['five', 'CD'], ['minutes', 'NNS'], ['or', 'CC'], ['so', 'RB'], ['of', 'IN'], ['_', 'CD'], ['Roxbury', 'NNP'], ['_', 'NN'], ['play', 'NN'], ['very', 'RB'], ['much', 'RB'], ['like', 'IN'], ['one', 'CD'], ['of', 'IN'], ['the', 'DT'], ['original', 'JJ'], ['``', '``'], ['Roxbury', 'NNP'], ['Guys', 'NNP'], [\"''\", \"''\"], ['skits', 'NNS'], ['.', '.']], [['With', 'IN'], ['``', '``'], ['What', 'WP'], ['Is', 'VBZ'], ['Love', 'NNP'], ['?', '.'], [\"''\", \"''\"]], [['blaring', 'VBG'], ['on', 'IN'], ['the', 'DT'], ['soundtrack', 'NN'], [',', ','], ['the', 'DT'], ['brotherly', 'JJ'], ['duo', 'NN'], ['of', 'IN'], ['Doug', 'NNP'], ['and', 'CC'], ['Steve', 'NNP'], ['Butabi', 'NNP'], ['-LRB-', '-LRB-'], ['Chris', 'NNP'], ['Kattan', 'NNP'], ['and', 'CC'], ['Will', 'NNP'], ['Ferrell', 'NNP'], ['-RRB-', '-RRB-'], ['bob', 'VBP'], ['their', 'PRP$'], ['heads', 'NNS'], [',', ','], ['scope', 'NN'], ['out', 'IN'], ['``', '``'], ['hotties', 'NNS'], [\"''\", \"''\"], ['at', 'IN'], ['clubs', 'NNS'], [',', ','], ['and', 'CC'], ['then', 'RB'], ['bump', 'VB'], ['a', 'DT'], ['select', 'JJ'], ['few', 'JJ'], ['with', 'IN'], ['violent', 'JJ'], ['pelvic', 'JJ'], ['thrusts', 'NNS'], ['.', '.']], [['There', 'EX'], ['is', 'VBZ'], ['one', 'CD'], ['crucial', 'JJ'], ['difference', 'NN'], [',', ','], ['however', 'RB'], ['--', ':'], ['these', 'DT'], ['guys', 'NNS'], ['speak', 'VBP'], ['.', '.']], [['That', 'DT'], ['little', 'JJ'], ['fact', 'NN'], ['has', 'VBZ'], ['been', 'VBN'], ['used', 'VBN'], ['as', 'IN'], ['justification', 'NN'], ['for', 'IN'], ['the', 'DT'], ['film', 'NN'], [\"'s\", 'POS'], ['existence', 'NN'], [',', ','], ['that', 'IN'], ['the', 'DT'], ['Butabis', 'NNP'], [\"'\", 'POS'], ['newfound', 'JJ'], ['capacity', 'NN'], ['for', 'IN'], ['speech', 'NN'], ['would', 'MD'], ['open', 'VB'], ['up', 'RP'], ['a', 'DT'], ['whole', 'JJ'], ['new', 'JJ'], ['set', 'NN'], ['of', 'IN'], ['doors', 'NNS'], ['for', 'IN'], ['the', 'DT'], ['characters', 'NNS'], ['.', '.']], [['The', 'DT'], ['doors', 'NNS'], ['opened', 'VBN'], ['by', 'IN'], ['director', 'NN'], ['John', 'NNP'], ['Fortenberry', 'NNP'], ['and', 'CC'], ['screenwriters', 'NNS'], ['Steve', 'NNP'], ['Koren', 'NNP'], [',', ','], ['Ferrell', 'NNP'], [',', ','], ['and', 'CC'], ['Kattan', 'NNP'], ['are', 'VBP'], ['new', 'JJ'], [',', ','], ['that', 'DT'], [\"'s\", 'VBZ'], ['for', 'IN'], ['sure', 'JJ'], [',', ','], ['but', 'CC'], ['they', 'PRP'], ['all', 'DT'], ['lead', 'VBP'], ['to', 'TO'], ['comic', 'JJ'], ['dead', 'JJ'], ['ends', 'NNS'], ['.', '.']], [['There', 'EX'], ['is', 'VBZ'], ['no', 'DT'], ['story', 'NN'], ['per', 'FW'], ['se', 'FW'], [',', ','], ['only', 'RB'], ['a', 'DT'], ['loosely', 'RB'], ['structured', 'VBN'], ['and', 'CC'], ['linked', 'VBN'], ['series', 'NN'], ['of', 'IN'], ['subplots', 'NNS'], ['.', '.']], [['The', 'DT'], ['brothers', 'NNS'], ['literally', 'RB'], ['run', 'VBP'], ['into', 'IN'], ['-LRB-', '-LRB-'], ['or', 'CC'], [',', ','], ['rather', 'RB'], [',', ','], ['get', 'VB'], ['run', 'VBN'], ['into', 'IN'], [',', ','], ['as', 'IN'], ['in', 'IN'], ['by', 'IN'], ['car', 'NN'], ['-RRB-', '-RRB-'], ['Richard', 'NNP'], ['Grieco', 'NNP'], ['of', 'IN'], ['_', 'CD'], ['21_Jump_Street', 'NN'], ['_', 'CD'], ['fame', 'NN'], [',', ','], ['and', 'CC'], ['through', 'IN'], ['him', 'PRP'], ['they', 'PRP'], ['gain', 'VBP'], ['entrance', 'NN'], ['into', 'IN'], ['the', 'DT'], ['exclusive', 'JJ'], ['Roxbury', 'NNP'], ['club', 'NN'], ['.', '.']], [['There', 'RB'], [',', ','], ['they', 'PRP'], ['meet', 'VBP'], ['a', 'DT'], ['hotshot', 'NN'], ['club', 'NN'], ['owner', 'NN'], ['-LRB-', '-LRB-'], ['Chazz', 'NNP'], ['Palminteri', 'NNP'], [',', ','], ['conspicuously', 'RB'], ['uncredited', 'JJ'], ['--', ':'], ['can', 'MD'], ['you', 'PRP'], ['blame', 'VB'], ['him', 'PRP'], ['?', '.'], ['-RRB-', '-RRB-']], [[',', ','], ['who', 'WP'], ['takes', 'VBZ'], ['an', 'DT'], ['interest', 'NN'], ['in', 'IN'], ['an', 'DT'], ['idea', 'NN'], ['of', 'IN'], ['theirs', 'JJ'], ['.', '.']], [['Meanwhile', 'RB'], [',', ','], ['the', 'DT'], ['bros', 'NNS'], [\"'\", 'POS'], ['overbearing', 'JJ'], ['father', 'NN'], ['-LRB-', '-LRB-'], ['Dan', 'NNP'], ['Hedaya', 'NNP'], ['-RRB-', '-RRB-'], ['wants', 'VBZ'], ['them', 'PRP'], ['to', 'TO'], ['stop', 'VB'], ['clubbing', 'VBG'], ['.', '.']], [['When', 'WRB'], ['Doug', 'NNP'], ['refuses', 'VBZ'], ['and', 'CC'], ['the', 'DT'], ['dimwitted', 'JJ'], ['Steve', 'NNP'], ['obeys', 'VBZ'], ['his', 'PRP$'], ['father', 'NN'], [',', ','], ['a', 'DT'], ['rift', 'NN'], ['is', 'VBZ'], ['created', 'VBN'], ['between', 'IN'], ['the', 'DT'], ['two', 'CD'], ['.', '.']], [['The', 'DT'], ['narrative', 'JJ'], ['messiness', 'NN'], ['of', 'IN'], ['_', 'CD'], ['Roxbury', 'NNP'], ['_', 'NN'], ['would', 'MD'], ['have', 'VB'], ['been', 'VBN'], ['forgivable', 'JJ'], ['if', 'IN'], ['all', 'DT'], ['that', 'WDT'], ['went', 'VBD'], ['on', 'IN'], ['were', 'VBD'], ['the', 'DT'], ['slightest', 'JJS'], ['bit', 'NN'], ['funny', 'JJ'], [',', ','], ['but', 'CC'], ['virtually', 'RB'], ['none', 'NN'], ['of', 'IN'], ['it', 'PRP'], ['is', 'VBZ'], ['.', '.']], [['The', 'DT'], ['assembled', 'VBN'], ['press', 'NN'], ['audience', 'NN'], ['mostly', 'RB'], ['sat', 'VBD'], ['stonily', 'RB'], ['silent', 'JJ'], ['throughout', 'IN'], ['the', 'DT'], ['entire', 'JJ'], ['film', 'NN'], [',', ','], ['with', 'IN'], ['the', 'DT'], ['one', 'CD'], ['big', 'JJ'], ['exception', 'NN'], ['being', 'VBG'], ['a', 'DT'], ['big', 'JJ'], ['laugh', 'NN'], ['near', 'IN'], ['the', 'DT'], ['end', 'NN'], ['.', '.']], [['Alas', 'RB'], [',', ','], ['the', 'DT'], ['joke', 'NN'], ['--', ':'], ['a', 'DT'], ['rather', 'RB'], ['lazy', 'JJ'], ['takeoff', 'NN'], ['on', 'IN'], ['_', 'NN'], ['Jerry_Maguire', 'NN'], ['_', 'CD'], ['--', ':'], ['will', 'MD'], ['only', 'RB'], ['strike', 'VB'], ['a', 'DT'], ['chord', 'NN'], ['with', 'IN'], ['people', 'NNS'], ['who', 'WP'], ['have', 'VBP'], ['seen', 'VBN'], ['that', 'IN'], ['film', 'NN'], ['.', '.']], [['Granted', 'VBN'], [',', ','], ['a', 'DT'], ['lot', 'NN'], ['of', 'IN'], ['people', 'NNS'], ['_', 'VBP'], ['have', 'VBP'], ['_', 'RB'], ['seen', 'VBN'], ['_', 'NN'], ['Jerry_Maguire', 'NN'], ['_', 'NN'], [',', ','], ['but', 'CC'], ['the', 'DT'], ['fact', 'NN'], ['that', 'IN'], ['the', 'DT'], ['film', 'NN'], [\"'s\", 'POS'], ['best', 'JJS'], ['joke', 'NN'], ['is', 'VBZ'], ['completely', 'RB'], ['dependent', 'JJ'], ['on', 'IN'], ['one', 'CD'], [\"'s\", 'POS'], ['familiarity', 'NN'], ['with', 'IN'], ['another', 'DT'], ['film', 'NN'], ['says', 'VBZ'], ['a', 'DT'], ['lot', 'NN'], ['about', 'IN'], ['_', 'CD'], ['Roxbury', 'NNP'], ['_', 'NN'], [\"'s\", 'POS'], ['lack', 'NN'], ['of', 'IN'], ['inspiration', 'NN'], ['.', '.']], [['That', 'DT'], ['lack', 'NN'], ['of', 'IN'], ['inspiration', 'NN'], ['can', 'MD'], ['be', 'VB'], ['traced', 'VBN'], ['back', 'RB'], ['to', 'TO'], ['the', 'DT'], ['insipid', 'JJ'], ['characters', 'NNS'], ['themselves', 'PRP'], ['.', '.']], [['Like', 'IN'], ['too', 'RB'], ['many', 'JJ'], ['of', 'IN'], ['the', 'DT'], ['skits', 'NNS'], ['on', 'IN'], ['the', 'DT'], ['current', 'JJ'], ['incarnation', 'NN'], ['of', 'IN'], ['_', 'CD'], ['Saturday_Night_Live', 'JJ'], ['_', 'NN'], [',', ','], ['``', '``'], ['The', 'DT'], ['Roxbury', 'NNP'], ['Guys', 'NNP'], [\"''\", \"''\"], ['is', 'VBZ'], ['a', 'DT'], ['one-joke', 'JJ'], ['sketch', 'NN'], ['that', 'WDT'], ['never', 'RB'], ['once', 'RB'], ['suggests', 'VBZ'], ['that', 'IN'], ['the', 'DT'], ['characters', 'NNS'], ['have', 'VBP'], ['enough', 'RB'], ['comic', 'JJ'], ['life', 'NN'], ['in', 'IN'], ['them', 'PRP'], ['to', 'TO'], ['survive', 'VB'], ['outside', 'NN'], ['of', 'IN'], ['the', 'DT'], ['sketch', 'NN'], ['context', 'NN'], ['.', '.']], [['After', 'IN'], ['watching', 'VBG'], ['one', 'CD'], ['of', 'IN'], ['the', 'DT'], ['``', '``'], ['Roxbury', 'NNP'], [\"''\", \"''\"], ['skits', 'NNS'], ['on', 'IN'], ['SNL', 'NNP'], [',', ','], ['this', 'DT'], ['is', 'VBZ'], ['what', 'WP'], ['you', 'PRP'], ['come', 'VBP'], ['away', 'RB'], ['with', 'IN'], ['from', 'IN'], ['the', 'DT'], ['characters', 'NNS'], [':', ':'], ['they', 'PRP'], ['bob', 'VBP'], ['their', 'PRP$'], ['heads', 'NNS'], ['to', 'TO'], ['``', '``'], ['What', 'WP'], ['Is', 'VBZ'], ['Love', 'NNP'], ['?', '.'], [\"''\", \"''\"]], [[',', ','], ['bump', 'VB'], ['unsuspecting', 'JJ'], ['women', 'NNS'], [',', ','], ['and', 'CC'], ['...', ':'], ['that', 'DT'], [\"'s\", 'VBZ'], ['all', 'DT'], ['.', '.']], [['After', 'IN'], ['watching', 'VBG'], ['_', 'CD'], ['A_Night_at_the_Roxbury', 'NN'], ['_', 'NN'], [',', ','], ['you', 'PRP'], [\"'ll\", 'MD'], ['be', 'VB'], ['left', 'VBN'], ['with', 'IN'], ['exactly', 'RB'], ['the', 'DT'], ['same', 'JJ'], ['.', '.']]]}\n"]}],"source":["with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n","  line_cnt = 0\n","  sum = 0\n","  for line in f:\n","    print(line.strip())\n","    line_cnt += 1\n","    if line_cnt > 4:\n","      break\n","\n","print(reviews[999])"]},{"cell_type":"markdown","metadata":{"id":"Mml4nOtIUBhn"},"source":["Lexica such as this can be used to solve\n","the classification task without using Machine Learning. For example, one might look up every word $w_1 ... w_n$ in a document, and compute a **binary score**\n","$S_{binary}$ by counting how many words have a positive or a\n","negative label in the sentiment lexicon $SLex$.\n","\n","$$S_{binary}(w_1 w_2 ... w_n) = \\sum_{i = 1}^{n}\\text{sign}(SLex\\big[w_i\\big])$$\n","\n","where $\\text{sign}(SLex\\big[w_i\\big])$ refers to the polarity of $w_i$.\n","\n","**Threshold.** On average, there are more positive than negative words per review (~7.13 more positive than negative per review) to take this bias into account you should use a threshold of **8** (roughly the bias itself) to make it harder to classify as positive.\n","\n","$$\n","\\text{classify}(S_{binary}(w_1 w_2 ... w_n)) = \\bigg\\{\\begin{array}{ll}\n","        \\text{positive} & \\text{if } S_{binary}(w_1w_2...w_n) > threshold\\\\\n","        \\text{negative} & \\text{otherwise}\n","        \\end{array}\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"tOFnMvbeeZrc"},"source":["#### (Q1.1) Implement this approach and report its classification accuracy. (1 pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ED2aTEYutW1-"},"outputs":[],"source":["# YOUR CODE HERE\n","\n","lexicon_dict = {}\n","threshold = 8\n","token_results = []\n","\n","#Parsing sentiment lexicon\n","with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","\n","        temp = line.split()\n","        word = temp[2]\n","        sent = temp[-1]\n","        \n","        word_idx = word.find('=') + 1\n","        sent_idx = sent.find('=') + 1\n","\n","        word = word[word_idx:]\n","        sent = sent[sent_idx:]\n","\n","        if sent == 'positive':\n","            sign = 1\n","        elif sent == 'negative':\n","            sign = -1\n","        else:\n","            sign = 0\n","\n","        #dictionary of words - sentiments\n","        lexicon_dict[word] = sign\n","\n","\n","for review in reviews:\n","    sum=0\n","    for sentence in review[\"content\"]:\n","        for token, pos_tag in sentence:\n","            token = token.lower()\n","            #get every word value from the dict\n","            if token in lexicon_dict.keys():\n","                s = lexicon_dict[token]\n","            else:\n","                s = 0\n","            #add all values in the document\n","            sum += s\n","    \n","    #sum must be greater than threshold\n","    if sum > threshold:\n","        prediction = 'POS'\n","    else:\n","        prediction ='NEG'\n","\n","    #final prediction\n","    if prediction == review[\"sentiment\"]:\n","        token_results.append(1)\n","    else:\n","        token_results.append(0)\n","        \n","                "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668517425379,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"iy528EUTphz5","outputId":"bc11bca3-0545-4d21-e493-ae7db415c7cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.68\n"]}],"source":["# token_results should be a list of binary indicators; for example [1, 0, 1, ...] \n","# where 1 indicates a correct classification and 0 an incorrect classification.\n","# token_results = # ..\n","token_accuracy = token_results.count(1) / len(token_results)\n","print(\"Accuracy: %0.2f\" % token_accuracy)"]},{"cell_type":"markdown","metadata":{"id":"Twox0s_3eS0V"},"source":["As the sentiment lexicon also has information about the **magnitude** of\n","sentiment (e.g., *“excellent\"* has the same sentiment _polarity_ as *“good\"* but it has a higher magnitude), we can take a more fine-grained approach by adding up all\n","sentiment scores, and deciding the polarity of the movie review using\n","the sign of the weighted score $S_{weighted}$.\n","\n","$$S_{weighted}(w_1w_2...w_n) = \\sum_{i = 1}^{n}SLex\\big[w_i\\big]$$\n","\n","\n","Make sure you define an appropriate threshold for this approach.\n","\n","#### (Q1.2) Now incorporate magnitude information and report the classification accuracy. Don't forget to use the threshold. (1pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qG3hUDnPtkhS"},"outputs":[],"source":["# YOUR CODE HERE\n","\n","lexicon_dict = {}\n","threshold = 8\n","magnitude_results = []\n","\n","#Parsing sentiment lexicon\n","with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","\n","        temp = line.split()\n","        word = temp[2]\n","        sent = temp[-1]\n","        magn = temp[0]\n","\n","        \n","        word_idx = word.find('=') + 1\n","        sent_idx = sent.find('=') + 1\n","        magn_idx = magn.find('=') + 1\n","\n","        word = word[word_idx:]\n","        sent = sent[sent_idx:]\n","        magn = magn[magn_idx:]\n","\n","        if magn == 'weaksubj':\n","            mult = 1\n","        elif magn == 'strongsubj':\n","            mult = 2 \n","        else :\n","            mult = 0\n","\n","        if sent == 'positive':\n","            sign = 1\n","        elif sent == 'negative':\n","            sign = -1\n","        else:\n","            sign = 0\n","\n","        #dict now has the magnitude values encoded\n","        #possible values: [-2, -1, 0, 1, 2]\n","        lexicon_dict[word] = sign * mult\n","\n","\n","#calculating the new threshold\n","sum=0\n","for review in reviews:\n","    possum=0\n","    negsum=0\n","    #calculate the difference in scores for each document\n","    #Now also taking magnitude into account by using our new dict\n","    for sentence in review[\"content\"]:\n","        for token, pos_tag in sentence:\n","            token = token.lower()\n","            if token in lexicon_dict.keys():\n","                if lexicon_dict[token] > 0:\n","                    possum += lexicon_dict[token]\n","                else:\n","                    negsum += (-lexicon_dict[token])\n","    sum += (possum-negsum)\n","\n","#compute the average difference\n","threshold = sum / len(reviews)         \n","threshold = int(threshold) + 1\n","\n","#predict\n","for review in reviews:\n","    sum=0\n","    for sentence in review[\"content\"]:\n","        for token, pos_tag in sentence:\n","            token = token.lower()\n","            #get every word value from the dict\n","            if token in lexicon_dict.keys():\n","                s = lexicon_dict[token]\n","            else:\n","                s = 0\n","            sum += s\n","        \n","    if sum > threshold:\n","        prediction = 'POS'\n","    else:\n","        prediction ='NEG'\n","\n","    #final prediction\n","    if prediction == review[\"sentiment\"]:\n","        magnitude_results.append(1)\n","    else:\n","        magnitude_results.append(0)\n","        \n","                "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1668517429106,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"9vVk7CvDpyka","outputId":"a20a8d34-6b80-4688-ff54-8e4ecaafd286"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.70\n"]}],"source":["# magnitude_results = # a list of binary indicators\n","magnitude_accuracy = magnitude_results.count(1) / len(magnitude_results)\n","print(\"Accuracy: %0.2f\" % magnitude_accuracy)"]},{"cell_type":"markdown","metadata":{"id":"h9SHoGPfsAHV"},"source":["#### (Q.1.3) Make a barplot of the two results (0.5pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1668517429107,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"8LgBcYcXsEk3","outputId":"9675fe32-fa56-46a0-c150-f88772845cb4"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 576x720 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# YOUR CODE HERE\n","\n","data = {'Unweighted': token_accuracy, 'Weighted': magnitude_accuracy}\n","\n","accs = list(data.keys())\n","methods = list(data.values())\n","fig = plt.figure(figsize = (8, 10))\n"," \n","plt.bar(accs, methods, color ='green',width = 0.4)\n","plt.title(\"Unweighted Predictions vs Weighted Predictions\")\n","plt.ylabel(\"Accuracy\")\n","plt.yticks(np.arange(0, 1.01, step=0.05))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"sNhS8OCVxMHd"},"source":["#### (Q1.4) A better threshold (1pt)\n","Above we have defined a threshold to account for an inherent bias in the dataset: there are more positive than negative words per review.\n","However, that threshold does not take into account *document length*. Explain why this is a problem and implement an alternative way to compute the threshold."]},{"cell_type":"markdown","metadata":{"id":"xo7gk1I-omLI"},"source":["By not taking document length into account, a longer review will naturally affect the threshold outcome a lot more than a shorter review. Because we use the numerical difference between positive and negative words in each document, it's easier t ohave larger differences in longer documents. \n","\n","To solve this problem and have any review count the same towards the threshold computation, we can divide every document difference with its length. This way we obtain an average difference per word for this document. We sum all average differences together to obtain our sum. After that, we can add all document lengths together and divide by document number to obtain a document average length.\n","\n","The threshold is calculated by multiplying our sum with the average document length and dividing by document number."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3740,"status":"ok","timestamp":1668517432839,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"Dwt0B8h8aKjr","outputId":"f3f81d86-44ea-41bb-9d94-44434ada2661"},"outputs":[{"name":"stdout","output_type":"stream","text":["New threshold is 11\n","Accuracy: 0.70\n"]}],"source":["# YOUR CODE HERE\n","#calculating the threshold\n","sum=0\n","lens=[]\n","for review in reviews:\n","    possum=0\n","    negsum=0\n","    words = 0\n","    for sentence in review[\"content\"]:\n","        for token, pos_tag in sentence:\n","            token = token.lower()\n","            words += 1\n","            if token in lexicon_dict.keys():\n","                if lexicon_dict[token] > 0:\n","                    possum += lexicon_dict[token]\n","                else:\n","                    negsum += (-lexicon_dict[token])\n","    \n","    #Add average diffeence per word for each document\n","    sum += ((possum-negsum) / words)\n","    lens.append(words)\n","\n","#average document length\n","avg_len = np.sum(lens) / len(lens)\n","\n","#final threshold\n","threshold = (sum * avg_len) / len(reviews)    \n","threshold = int(threshold) + 1\n","\n","print(\"New threshold is \" + str(threshold))\n","\n","#predict\n","for review in reviews:\n","    sum=0\n","    for sentence in review[\"content\"]:\n","        for token, pos_tag in sentence:\n","            token = token.lower()\n","            if token in lexicon_dict.keys():\n","                s = lexicon_dict[token]\n","            else:\n","                s = 0\n","            sum += s\n","        \n","    if sum > threshold:\n","        prediction = 'POS'\n","    else:\n","        prediction ='NEG'\n","\n","    if prediction == review[\"sentiment\"]:\n","        magnitude_results.append(1)\n","    else:\n","        magnitude_results.append(0)\n","\n","\n","magnitude_accuracy = magnitude_results.count(1) / len(magnitude_results)\n","print(\"Accuracy: %0.2f\" % magnitude_accuracy)\n"]},{"cell_type":"markdown","metadata":{"id":"LibV4nR89BXb"},"source":["# (2) Naive Bayes (9.5pts)"]},{"cell_type":"markdown","metadata":{"id":"fnF9adQnuwia"},"source":["\n","Your second task is to program a simple Machine Learning approach that operates\n","on a simple Bag-of-Words (BoW) representation of the text data, as\n","described by Pang et al. (2002). In this approach, the only features we\n","will consider are the words in the text themselves, without bringing in\n","external sources of information. The BoW model is a popular way of\n","representing texts as vectors, making it\n","easy to apply classical Machine Learning algorithms on NLP tasks.\n","However, the BoW representation is also very crude, since it discards\n","all information related to word order and grammatical structure in the\n","original text—as the name suggests.\n","\n","## Writing your own classifier (4pts)\n","\n","Write your own code to implement the Naive Bayes (NB) classifier. As\n","a reminder, the Naive Bayes classifier works according to the following\n","equation:\n","$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} P(c|\\bar{f}) = \\operatorname*{arg\\,max}_{c \\in C} P(c)\\prod^n_{i=1} P(f_i|c)$$\n","where $C = \\{ \\text{POS}, \\text{NEG} \\}$ is the set of possible classes,\n","$\\hat{c} \\in C$ is the most probable class, and $\\bar{f}$ is the feature\n","vector. Remember that we use the log of these probabilities when making\n","a prediction:\n","$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} \\Big\\{\\log P(c) + \\sum^n_{i=1} \\log P(f_i|c)\\Big\\}$$\n","\n","You can find more details about Naive Bayes in [Jurafsky &\n","Martin](https://web.stanford.edu/~jurafsky/slp3/). You can also look at\n","this helpful\n","[pseudo-code](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html).\n","\n","*Note: this section and the next aim to put you in a position to replicate\n","    Pang et al.'s Naive Bayes results. However, your numerical results\n","    will differ from theirs, as they used different data.*\n","\n","**You must write the Naive Bayes training and prediction code from\n","scratch.** You will not be given credit for using off-the-shelf Machine\n","Learning libraries.\n","\n","The data contains the text of the reviews, where each document consists\n","of the sentences in the review, the sentiment of the review and an index\n","(cv) that you will later use for cross-validation. The\n","text has already been tokenised and POS-tagged for you. Your algorithm\n","should read in the text, **lowercase it**, store the words and their\n","frequencies in an appropriate data structure that allows for easy\n","computation of the probabilities used in the Naive Bayes algorithm, and\n","then make predictions for new instances.\n"]},{"cell_type":"markdown","metadata":{"id":"vEpyQSBSkb33"},"source":["#### (Q2.1) Unseen words (1pt)\n","The presence of words in the test dataset that\n","have not been seen during training can cause probabilities in the Naive Bayes classifier to equal $0$.\n","These can be words which are unseen in both positive and negative training reviews (case 1), but also words which are seen in reviews _of only one sentiment class_ in the training dataset (case 2). In both cases, **you should skip these words for both classes**.  What would be the problem instead with skipping words only for one class in case 2? "]},{"cell_type":"markdown","metadata":{"id":"BanFiYYnoxDW"},"source":["By skipping words only for one class, we use words that only affect one of the two conditional probablilities. This means that more words affect predictions towards one class than the other, unfairly increasing the scores for this class every time such a word occurs. To make fair predictions, we need the conditional probability to be affected by the same words for each class."]},{"cell_type":"markdown","metadata":{"id":"gsZRhaI3WvzC"},"source":["#### (Q2.2) Train your classifier on (positive and negative) reviews with cv-value 000-899, and test it on the remaining (positive and negative) reviews cv900–cv999.  Report results using classification accuracy as your evaluation metric. Your  features are the word vocabulary. The value of a feature is the count of that feature (word) in the document. (2pts)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4220,"status":"ok","timestamp":1668517437045,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"G7zaJYGFvIJ3","outputId":"1de97fb4-031d-4e1c-db17-fa8f0cc6eb65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.835\n"]}],"source":["# YOUR CODE HERE\n","\n","#computes the number each word occurs for every class \n","def class_frequencies(trainset):\n","    \"\"\"\n","    Computes the number each word occurs for every class for the given dataset\n","\n","    Args:\n","      trainset: the dataset in which we want to compute the frequencies\n","    Returns:\n","      pos_freq: the frequency for the positive class\n","      neg_freq: the frequency for the negative class\n","    \"\"\"\n","    pos_freq = {}\n","    neg_freq = {}\n","\n","    for bag in trainset['pos']:\n","        for token, v in bag.items():\n","            if token in pos_freq.keys():\n","                pos_freq[token] += v\n","            else:\n","                pos_freq[token] = v\n","\n","    for bag in trainset['neg']:\n","        for token, v in bag.items():\n","            if token in neg_freq.keys():\n","                neg_freq[token] += v\n","            else:\n","                neg_freq[token] = v\n","\n","\n","    return pos_freq, neg_freq\n","\n","#returns the dataset vocabulary\n","def compute_vocab(documents):\n","    \"\"\"\n","    Computes the vocabulary for the given dataset\n","\n","    Args:\n","      documents: the input dataset from which we want to extract the vocabulary\n","    Returns:\n","      pos_freq: the frequency for the positive class\n","      neg_freq: the frequency for the negative class\n","    \"\"\"\n","    vocab = set()\n","    for document in documents['pos']:  \n","        vocab.update(set(document.keys()))\n","    for document in documents['neg']:  \n","        vocab.update(set(document.keys()))\n","    return vocab\n","\n","#number of documents for each class\n","def class_counts(docs):\n","    \"\"\"\n","    Computes the number of reviews for each class\n","\n","    Args:\n","      docs: the input data, from which we will determine the number \n","      of positive and negative reviews\n","    Returns:\n","      pos: the number of positive reviews\n","      neg: the number of negative reviews\n","    \"\"\"\n","    neg = len(docs['pos'])\n","    pos = len(docs['neg'])\n","    return pos, neg\n","\n","def clear_dicts(c1, c2):\n","    \"\"\"\n","    Deletes the words from frequencies that do not exist in both classes\n","\n","    Args:\n","      c1: dictionary of words for the first class\n","      c2: dictionary of words for the second class\n","    Returns:\n","      new_c1: updated dictionary of the remaining words for the first class\n","      new_c2: updated dictionary of the remaining words for the second class\n","    \"\"\"\n","    keys1 = c1.keys()\n","    keys2 = c2.keys()\n","\n","    new_c1 = {} \n","    new_c2 = {}\n","\n","    for word in keys1:\n","        if word in keys2:\n","            new_c1[word] = c1[word]\n","\n","    for word in keys2:\n","        if word in keys1:\n","            new_c2[word] = c2[word]\n","\n","    return new_c1, new_c2\n","\n","def train_nb(trainset):\n","    \"\"\"\n","    Performs the training of the NB classifier by computing the trainset vocabulary,\n","    computing the class frequencies, keeping the words that appear in both classes with the \n","    already implemented functions and then computes the priors and the importance of a word in class.\n","\n","    Args:\n","      trainset: the dataset that we want to train the NB classifier with\n","    Returns:\n","      v: the trainset vocabulary\n","      priors: the priors\n","      conditionals: the conditionals\n","    \"\"\"\n","\n","    #compute trainset vocabulary\n","    v = compute_vocab(trainset)\n","    \n","    #compute class frequencies\n","    pos_f, neg_f = class_frequencies(trainset)\n","    \n","    #keep only words that appear in both classes\n","    pos_f, neg_f = clear_dicts(pos_f, neg_f)\n","    \n","    # compute priors\n","    pos_n, neg_n = class_counts(trainset)\n","    n = len(trainset['pos']) + len(trainset['neg'])\n","    priors = {'pos': pos_n/n, 'neg' : neg_n/n}\n","    \n","    pos_sum=0\n","    neg_sum=0\n","\n","    for freq in pos_f.values():\n","        pos_sum += freq\n","    for freq in neg_f.values():    \n","        neg_sum += freq\n","    \n","    conditionals = {}\n","  \n","    #compute importance of word in class\n","    for t in v:\n","        pos_count = 0\n","        neg_count = 0\n","        if t in pos_f.keys():\n","            pos_count = pos_f[t]\n","        if t in neg_f.keys():\n","            neg_count = neg_f[t]\n","\n","        # pos_cond = (pos_count+1) / pos_sum\n","        # neg_cond = (neg_count+1) / neg_sum\n","\n","        pos_cond = (pos_count) / pos_sum\n","        neg_cond = (neg_count) / neg_sum\n","\n","        conditionals[t] = (pos_cond,neg_cond)    \n","    \n","    \n","    return v, priors, conditionals\n","\n","\n","def test_nb(testset, priors, conditionals):\n","    \"\"\"\n","    Performs the testing of the NB classifier\n","\n","    Args:\n","      testset: the dataset that we want to test the NB classifier with\n","      priors: the priors (estimated before)\n","      conditionals: the conditionals (estimated before)\n","    Returns:\n","      nb_accuracy : the accuracy of the NB classifier in the test dataset\n","    \"\"\"\n","    predictions = []\n","    tests = testset['pos'] + testset['neg']\n","\n","    for document in testset['pos']:\n","        pos_score = np.log(priors['pos'])\n","        neg_score = np.log(priors['neg'])\n","\n","        for token in document.keys():\n","            if token in conditionals.keys():\n","                if conditionals[token][0] > 0 and conditionals[token][1] > 0:\n","                    pos_score += document[token] * np.log(conditionals[token][0])\n","                    neg_score += document[token] * np.log(conditionals[token][1])\n","\n","        if pos_score > neg_score:\n","            predictions.append(1)\n","        else:\n","            predictions.append(0)\n","    \n","    \n","    for document in testset['neg']:\n","        pos_score = np.log(priors['pos'])\n","        neg_score = np.log(priors['neg'])\n","\n","        for token in document.keys():\n","            if token in conditionals.keys():\n","                if conditionals[token][0] > 0 and conditionals[token][1] > 0:\n","                    pos_score += document[token] * np.log(conditionals[token][0])\n","                    neg_score += document[token] * np.log(conditionals[token][1])\n","\n","        if pos_score <= neg_score:\n","            predictions.append(1)\n","        else:\n","            predictions.append(0)\n","    \n","\n","    nb_accuracy = predictions.count(1) / len(predictions)\n","    print(\"Accuracy: %0.3f\" % nb_accuracy)\n","\n","    return nb_accuracy\n","\n","data = {'pos':[], 'neg':[]}\n","\n","for review in reviews:\n","    bag = {}\n","    for sentence in review[\"content\"]:\n","        for token, pos_tag in sentence:\n","            token = token.lower()\n","            if token in bag.keys():\n","                bag[token] += 1\n","            else:\n","                bag[token] = 1\n","    if review['sentiment'] == 'POS':\n","        data['pos'].append(bag)\n","    else:\n","        data['neg'].append(bag)\n","\n","\n","trainset = {'pos':data['pos'][0:900], 'neg':data['neg'][0:900]}\n","testset = {'pos':data['pos'][900:1000], 'neg':data['neg'][900:1000]}\n","\n","v, priors, conditionals = train_nb(trainset)\n","acc = test_nb(testset, priors, conditionals)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0INK-PBoM6CB"},"source":["#### (Q2.3) Would you consider accuracy to also be a good way to evaluate your classifier in a situation where 90% of your data instances are of positive movie reviews? (1pt)\n","\n","Simulate this scenario by keeping the positive reviews\n","data unchanged, but only using negative reviews cv000–cv089 for\n","training, and cv900–cv909 for testing. Calculate the classification\n","accuracy, and explain what changed."]},{"cell_type":"markdown","metadata":{"id":"oFbcsYlipBAw"},"source":["Accuracy is not a good metric if the classes are not balanced. If 90% of our data are positive, the priors for each class would be 0,9 and 0,1, which makes the classifier biased towards the positive class. Accuracy goes up if our model predicts (almost) all reviews to be positive, even though this does not generalize to a case with a good class distribution.\n","\n","In our example below, we get almost a 90% accuracy, because our classifier predicts almost everything as a positive review and, in most cases, is correct."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":715,"status":"ok","timestamp":1668517437743,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"GWDkt5ZrrFGp","outputId":"d880612d-68d1-4c9e-fd4e-3a4d59bb99b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.891\n"]}],"source":["# YOUR CODE HERE\n","\n","\n","new_trainset = {'pos':data['pos'][0:900], 'neg':data['neg'][0:90]}\n","new_testset = {'pos':data['pos'][900:1000], 'neg':data['neg'][900:910]}\n","\n","\n","v, priors, conditionals = train_nb(new_trainset)\n","acc = test_nb(new_testset, priors, conditionals)"]},{"cell_type":"markdown","metadata":{"id":"6wJzcHX3WUDm"},"source":["## Smoothing (1pt)\n","\n","As mentioned above, the presence of words in the test dataset that\n","have not been seen during training can cause probabilities in the Naive\n","Bayes classifier to be $0$, thus making that particular test instance\n","undecidable. The standard way to mitigate this effect (as well as to\n","give more clout to rare words) is to use smoothing, in which the\n","probability fraction\n","$$\\frac{\\text{count}(w_i, c)}{\\sum\\limits_{w\\in V} \\text{count}(w, c)}$$ for a word\n","$w_i$ becomes\n","$$\\frac{\\text{count}(w_i, c) + \\text{smoothing}(w_i)}{\\sum\\limits_{w\\in V} \\text{count}(w, c) + \\sum\\limits_{w \\in V} \\text{smoothing}(w)}$$\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PBNIcbwUWphC"},"source":["#### (Q2.4) Implement Laplace feature smoothing (1pt)\n","Implement Laplace smoothing, i.e., smoothing with a constant value ($smoothing(w) = \\kappa, \\forall w \\in V$), in your Naive\n","Bayes classifier’s code, and report the impact on performance. \n","Use $\\kappa = 1$."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1980,"status":"ok","timestamp":1668517439721,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"g03yflCc9kpW","outputId":"944ef8ab-0fe7-42f5-e397-daf171fd6dd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.830\n"]}],"source":["# YOUR CODE HERE\n","\n","def train_nb(trainset):\n","    \"\"\"\n","    Performs the training of the NB classifier by computing the trainset vocabulary,\n","    computing the class frequencies, keeping the words that appear in both classes with the \n","    already implemented functions and then computes the priors and the importance of a word in class.\n","    This time it's implemented using laplace smoothing to distribute some \"extra\" probability to unseen words.\n","\n","    Args:\n","      trainset: the dataset that we want to train the NB classifier with\n","    Returns:\n","      v: the trainset vocabulary\n","      priors: the priors\n","      conditionals: the conditionals\n","    \"\"\"\n","    #compute trainset vocabulary\n","    v = compute_vocab(trainset)\n","    #compute class frequencies\n","    pos_f, neg_f = class_frequencies(trainset)\n","    \n","    #keep only words that appear in both classes\n","    pos_f, neg_f = clear_dicts(pos_f, neg_f)\n","    \n","    # compute priors\n","    pos_n, neg_n = class_counts(trainset)\n","    n = len(trainset['pos']) + len(trainset['neg'])\n","    priors = {'pos': pos_n/n, 'neg' : neg_n/n}\n","\n","    pos_sum=0\n","    neg_sum=0\n","\n","    #smoothing\n","    for freq in pos_f.values():\n","        pos_sum += (freq+1)\n","    for freq in neg_f.values():    \n","        neg_sum += (freq+1)\n","\n","\n","    conditionals = {}\n","    #compute importance of word in class\n","    for t in v:\n","        pos_count = 0\n","        neg_count = 0\n","        if t in pos_f.keys():\n","            pos_count = pos_f[t]\n","        if t in neg_f.keys():\n","            neg_count = neg_f[t]\n","\n","        #smoothing: add +1 to each count\n","        pos_cond = (pos_count+1) / pos_sum\n","        neg_cond = (neg_count+1) / neg_sum\n","\n","\n","        conditionals[t] = (pos_cond,neg_cond)   \n","    \n","    return v, priors, conditionals\n","\n","\n","v, priors, conditionals = train_nb(trainset)\n","acc = test_nb(testset, priors, conditionals)\n"]},{"cell_type":"markdown","metadata":{"id":"ZiGcgwba87D5"},"source":["## Cross-Validation (1.5pts)\n","\n","A serious danger in using Machine Learning on small datasets, with many\n","iterations of slightly different versions of the algorithms, is ending up with Type III errors, also called the “testing hypotheses\n","suggested by the data” errors. This type of error occurs when we make\n","repeated improvements to our classifiers by playing with features and\n","their processing, but we don’t get a fresh, never-before seen test\n","dataset every time. Thus, we risk developing a classifier that gets better\n","and better on our data, but only gets worse at generalizing to new, unseen data. In other words, we risk developping a classifier that overfits.\n","\n","A simple method to guard against Type III errors is to use\n","Cross-Validation. In **N-fold Cross-Validation**, we divide the data into N\n","distinct chunks, or folds. Then, we repeat the experiment N times: each\n","time holding out one of the folds for testing, training our classifier\n","on the remaining N - 1 data folds, and reporting performance on the\n","held-out fold. We can use different strategies for dividing the data:\n","\n","-   Consecutive splitting:\n","  - cv000–cv099 = Split 1\n","  - cv100–cv199 = Split 2\n","  - etc.\n","  \n","-   Round-robin splitting (mod 10):\n","  - cv000, cv010, cv020, … = Split 1\n","  - cv001, cv011, cv021, … = Split 2\n","  - etc.\n","\n","-   Random sampling/splitting\n","  - Not used here (but you may choose to split this way in a non-educational situation)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8OeLcbSauGtR"},"source":["#### (Q2.5) Write the code to implement 10-fold cross-validation using round-robin splitting for your Naive Bayes classifier from Q2.4 and compute the 10 accuracies. Report the final performance, which is the average of the performances per fold. If all splits perform equally well, this is a good sign. (1pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7656,"status":"ok","timestamp":1668517447374,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"3KeCGPa7Nuzx","outputId":"baec56fb-10a2-40f8-9067-042f767667a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.775\n","Accuracy: 0.840\n","Accuracy: 0.815\n","Accuracy: 0.870\n","Accuracy: 0.785\n","Accuracy: 0.860\n","Accuracy: 0.810\n","Accuracy: 0.785\n","Accuracy: 0.830\n","Accuracy: 0.810\n"]}],"source":["# YOUR CODE HERE\n","k=10\n","\n","def rrsplit(data=data, k=10):\n","    \"\"\"\n","    Performs the round robin splitting method and calls the train_nb and test_nb\n","    function to do the cross validation \n","\n","    Args:\n","      data: data\n","      k = 10: the number of the folds of the cross validation\n","    Returns:\n","      accuracies: a list contatining the accuracy of the classifier for each fold\n","      vocab_size: the length of the vocabulary (for question 2.8)\n","    \"\"\"\n","    folds = [ {'pos':[], 'neg':[]} for index in range(k) ]\n","\n","    vocab_size = []\n","    accuracies = []\n","    for i in range(len(data['pos'])):\n","        idx = i % k\n","        folds[idx]['pos'].append(data['pos'][i])\n","        folds[idx]['neg'].append(data['neg'][i])\n","\n","\n","    for i in range(k):\n","        testset = folds[i]\n","        trainset = {'pos':[], 'neg':[]}\n","        for j in range(k):\n","            if i != j:\n","                trainset['pos'] += folds[j]['pos']\n","                trainset['neg'] += folds[j]['neg']\n","        \n","        v, priors, conditionals = train_nb(trainset)\n","        acc = test_nb(testset, priors, conditionals)\n","        accuracies.append(acc)\n","        vocab_size.append(len(v))\n","        \n","    # print(\"Mean Accuracy: %0.2f\" % sum(accuracies) / k)\n","    return accuracies, vocab_size\n","\n","accuracies, vocab_size = rrsplit(data)\n"]},{"cell_type":"markdown","metadata":{"id":"otdlsDXBNyOa"},"source":["#### (Q2.6) Report the variance of the 10 accuracy scores. (0.5pt)\n","\n","**Please report all future results using 10-fold cross-validation now\n","(unless told to use the held-out test set).** Note: you're not allowed to use a library for computing the variance. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1668517447375,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"ZoBQm1KuNzNR","outputId":"a6219c0b-5066-4ce0-d4dd-d0e6f449a349"},"outputs":[{"name":"stdout","output_type":"stream","text":["The mean of the 10 accuracy scores is 0.8180000000000002 and the variance is 0.00093\n"]}],"source":["# YOUR CODE HERE\n","\n","def get_mean(data):\n","    \"\"\"\n","    Computes the mean of the data given \n","\n","    Args:\n","      data: the data, from which we want to compute the mean\n","    Returns:\n","      mean: the mean of the data\n","    \"\"\"\n","    N = len(data)\n","    sum = 0\n","    for i in range(N):\n","        sum += data[i]\n","    mean = sum/N\n","    return mean\n","\n","def get_variance(data):\n","    \"\"\"\n","    Computes the variance of the data given \n","\n","    Args:\n","      data: the data, from which we want to compute the variance\n","    Returns:\n","      variance: the variance of the data\n","    \"\"\"\n","    M = len(data)\n","    s = 0\n","    m = get_mean(data)\n","    for j in range(M):\n","        s += (data[j]-m)**2\n","    var = s/M\n","    return var\n","\n","\n","mean = get_mean(accuracies)\n","var = get_variance(accuracies)\n","print(\"The mean of the 10 accuracy scores is\",mean ,\"and the variance is %0.5f\" %var)"]},{"cell_type":"markdown","metadata":{"id":"s6A2zX9_BRKm"},"source":["## Features, overfitting, and the curse of dimensionality\n","\n","In the Bag-of-Words model, ideally we would like each distinct word in\n","the text to be mapped to its own dimension in the output vector\n","representation. However, real world text is messy, and we need to decide\n","on what we consider to be a word. For example, is “`word`\" different\n","from “`Word`\", from “`word`”, or from “`words`\"? Too strict a\n","definition, and the number of features explodes, while our algorithm\n","fails to learn anything generalisable. Too lax, and we risk destroying\n","our learning signal. In the following section, you will learn about\n","confronting the feature sparsity and the overfitting problems as they\n","occur in NLP classification tasks."]},{"cell_type":"markdown","metadata":{"id":"EKK8FNt8VtcZ"},"source":["### Stemming (1.5pts)\n","\n","To make your algorithm more robust, use stemming and hash different inflections of a word to the same feature in the BoW vector space. Please use the [Porter stemming\n","    algorithm](http://www.nltk.org/howto/stem.html) from NLTK.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxtCul1IrBi_"},"outputs":[],"source":["# YOUR CODE HERE\n","\n","data_stem = {'pos':[], 'neg':[]}\n","stemmer = PorterStemmer()\n","\n","for review in reviews:\n","    bag = {}\n","    for sentence in review[\"content\"]:\n","        for token, pos_tag in sentence:\n","            # token = use stemming on each token while parsing the data\n","            token = stemmer.stem(token.lower())\n","            if token in bag.keys():\n","                bag[token] += 1\n","            else:\n","                bag[token] = 1\n","    if review['sentiment'] == 'POS':\n","        data_stem['pos'].append(bag)\n","    else:\n","        data_stem['neg'].append(bag)\n","\n","\n","trainset_stem = {'pos':data_stem['pos'][0:900], 'neg':data_stem['neg'][0:900]}\n","testset_stem = {'pos':data_stem['pos'][900:1000], 'neg':data_stem['neg'][900:1000]}\n","\n","# v, priors, conditionals = train_nb(trainset_stem)\n","# acc = test_nb(testset_stem, priors, conditionals)\n"]},{"cell_type":"markdown","metadata":{"id":"6SrJ1BeLXTnk"},"source":["#### (Q2.7): How does the performance of your classifier change when you use stemming on your training and test datasets? (1pt)\n","Use cross-validation to evaluate the classifier. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5681,"status":"ok","timestamp":1668517478341,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"gYqKBOiIrInT","outputId":"cea8d68a-b308-48bc-c395-178f0217b129"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.765\n","Accuracy: 0.835\n","Accuracy: 0.805\n","Accuracy: 0.875\n","Accuracy: 0.790\n","Accuracy: 0.845\n","Accuracy: 0.820\n","Accuracy: 0.790\n","Accuracy: 0.825\n","Accuracy: 0.810\n","The mean of the 10 accuracy scores is 0.8160000000000001 and the variance is 0.00089\n"]}],"source":["# YOUR ANSWER HERE\n","accuracies, vocab_size_stemmer = rrsplit(data_stem)\n","mean = get_mean(accuracies)\n","var = get_variance(accuracies)\n","print(\"The mean of the 10 accuracy scores is\",mean ,\"and the variance is %0.5f\" %var)"]},{"cell_type":"markdown","metadata":{"id":"JkDHVq_1XUVP"},"source":["#### (Q2.8) What happens to the number of features (i.e., the size of the vocabulary) when using stemming as opposed to (Q2.4)? (0.5pt)\n","Give actual numbers. You can use the held-out training set to determine these."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1668518301698,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"MA3vee5-rJyy","outputId":"691f9295-580f-4f7f-914e-a49c96a81c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary size with the use of Stemmer : [32371, 32482, 32545, 32498, 32699, 32439, 32440, 32493, 32576, 32667] vs without using Stemmer : [45329, 45392, 45438, 45389, 45648, 45296, 45365, 45409, 45557, 45642]\n"]}],"source":["\"\"\"\n","A simple for loop to compare how Stemmer affects the vocabulary size\n","\"\"\"\n","\n","print(\"Vocabulary size with the use of Stemmer :\", vocab_size_stemmer, \"vs without using Stemmer :\" ,vocab_size)\n","\n","#for i in range(len(vocab_size_stemmer)):\n","#    print(\"Vocabulary size with the use of Stemmer ( fold\",i,\") :\", vocab_size_stemmer[i], \"vs without using Stemmer :\" ,vocab_size[i])"]},{"cell_type":"markdown","metadata":{"id":"SoazfxbNV5Lq"},"source":["### N-grams (1.5pts)\n","\n","A simple way of retaining some of the word\n","order information when using bag-of-words representations is to use **n-gram** features. \n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OHjy3I7-qWiu"},"source":["#### (Q2.9) Retrain your classifier from (Q2.4) using **unigrams+bigrams** and **unigrams+bigrams+trigrams** as features. (1pt)\n","Report accuracy and compare it with that of the approaches you have previously implemented. You are allowed to use NLTK to build n-grams from sentences."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107852,"status":"ok","timestamp":1668518056752,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"eYuKMTOpq9jz","outputId":"6003977a-0372-4096-9f49-26967baef299"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.790\n","Accuracy: 0.835\n","Accuracy: 0.805\n","Accuracy: 0.885\n","Accuracy: 0.800\n","Accuracy: 0.860\n","Accuracy: 0.830\n","Accuracy: 0.835\n","Accuracy: 0.830\n","Accuracy: 0.830\n","The mean of the 10 accuracy scores for unigrams + bigrams is 0.8300000000000001 and the variance is 0.00071\n","Accuracy: 0.780\n","Accuracy: 0.870\n","Accuracy: 0.815\n","Accuracy: 0.880\n","Accuracy: 0.810\n","Accuracy: 0.870\n","Accuracy: 0.835\n","Accuracy: 0.845\n","Accuracy: 0.840\n","Accuracy: 0.830\n","The mean of the 10 accuracy scores for unigrams + bigrams + trigrams is 0.8374999999999998 and the variance is 0.00086\n"]}],"source":["# YOUR CODE HERE\n","\n","# tri = True\n","# tri = False\n","\n","def build_ngrams(tri = False):\n","    \"\"\"\n","    Computes the bag of words containing bigrams and trigrams according to the input arguement. \n","\n","    Args:\n","      tri: Boolean, if true then this function computes the BoW containing unigrams+bigrams+trigrams,\n","      else if it is false, the BoW will consist only of unigrams+bigrams\n","    Returns:\n","      data_ngrams: the data that contain the unigrams+bigrams(+trigrams) and the sentiment of the review\n","    \"\"\"\n","    \n","    data_ngrams = {'pos':[], 'neg':[]}\n","\n","    for review in reviews:\n","        bag = {}\n","        unigrams = []\n","        for sentence in review[\"content\"]:\n","            for token, pos_tag in sentence:\n","                token = token.lower()\n","                unigrams.append(token)\n","                if token in bag.keys():\n","                    bag[token] += 1\n","                else:\n","                    bag[token] = 1\n","\n","        bigrams = [' '.join(e) for e in ngrams(unigrams,2)]\n","        for token in bigrams:\n","            if token in bag.keys():\n","                bag[token] += 1\n","            else:\n","                bag[token] = 1\n","\n","        if tri:\n","            trigrams = [' '.join(e) for e in ngrams(unigrams,3)]\n","            for token in trigrams:\n","                if token in bag.keys():\n","                    bag[token] += 1\n","                else:\n","                    bag[token] = 1\n","\n","\n","        if review['sentiment'] == 'POS':\n","            data_ngrams['pos'].append(bag)\n","        else:\n","            data_ngrams['neg'].append(bag)\n","\n","    return data_ngrams\n","\n","\n","# trainset_ngrams = {'pos':data_ngrams['pos'][0:900], 'neg':data_ngrams['neg'][0:900]}\n","# testset_ngrams = {'pos':data_ngrams['pos'][900:1000], 'neg':data_ngrams['neg'][900:1000]}\n","\n","# v, priors, conditionals = train_nb(trainset_ngrams)\n","# acc = test_nb(testset_ngrams, priors, conditionals)\n","\n","\n","\n","data_ngrams = build_ngrams(False)\n","accuracies, vocab_sizes1 = rrsplit(data_ngrams)\n","mean = get_mean(accuracies)\n","var = get_variance(accuracies)\n","print(\"The mean of the 10 accuracy scores for unigrams + bigrams is\",mean ,\"and the variance is %0.5f\" %var)\n","\n","data_ngrams = build_ngrams(True)\n","accuracies, vocab_sizes2 = rrsplit(data_ngrams)\n","mean = get_mean(accuracies)\n","var = get_variance(accuracies)\n","print(\"The mean of the 10 accuracy scores for unigrams + bigrams + trigrams is\",mean ,\"and the variance is %0.5f\" %var)\n"]},{"cell_type":"markdown","metadata":{"id":"dVrGGArkrWoL"},"source":["\n","#### Q2.10: How many features does the BoW model have to take into account now? (0.5pt)\n","How would you expect the number of features to increase theoretically (e.g., linear, square, cubed, exponential)? How does this number compare, in practice, to the number of features at (Q2.8)?\n","\n","Use the held-out training set once again for this.\n"]},{"cell_type":"markdown","metadata":{"id":"yEGZ9SV8pPaa"},"source":["*Write your answer here.*\n","\n","We see that when we are using unigrams+bigrams, the size of the vocabulary is 471032. If we use unigrams+bigrams+trigrams, the size of the vocabulary is 1416686. The difference in the size between the two cases is 945654, meaning the vocabulary in the second case is approximately 3 times bigger than the one in the first case. So we expect that the vocabulary size will increase even more if we use ngrams with n >= 3."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12174,"status":"ok","timestamp":1668517590304,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"_z8sAJeUrdtM","outputId":"4bca55d7-fff0-480f-db95-ed9446d21979"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.845\n","The vocab size using unigrams+bigrams is  471032\n","Accuracy: 0.835\n","The vocab size using unigrams+bigrams+trigrams is  1416686\n"]}],"source":["data_ngrams = build_ngrams(False)\n","trainset_ngrams = {'pos':data_ngrams['pos'][0:900], 'neg':data_ngrams['neg'][0:900]}\n","testset_ngrams = {'pos':data_ngrams['pos'][900:1000], 'neg':data_ngrams['neg'][900:1000]}\n","v, priors, conditionals = train_nb(trainset_ngrams)\n","acc = test_nb(testset_ngrams, priors, conditionals)\n","#print(len(v), acc)\n","print(\"The vocab size using unigrams+bigrams is \" ,len(v))\n","\n","data_ngrams = build_ngrams(True)\n","trainset_ngrams = {'pos':data_ngrams['pos'][0:900], 'neg':data_ngrams['neg'][0:900]}\n","testset_ngrams = {'pos':data_ngrams['pos'][900:1000], 'neg':data_ngrams['neg'][900:1000]}\n","v, priors, conditionals = train_nb(trainset_ngrams)\n","acc = test_nb(testset_ngrams, priors, conditionals)\n","#print(len(v), acc)\n","print(\"The vocab size using unigrams+bigrams+trigrams is \" ,len(v))\n"]},{"cell_type":"markdown","metadata":{"id":"CHWKDL3YV6vh"},"source":["# (3) Support Vector Machines (4pts)"]},{"cell_type":"markdown","metadata":{"id":"hJSYhcVaoJGt"},"source":["Though simple to understand, implement, and debug, one\n","major problem with the Naive Bayes classifier is that its performance\n","deteriorates (becomes skewed) when it is being used with features which\n","are not independent (i.e., are correlated). Another popular classifier\n","that doesn’t scale as well to big data, and is not as simple to debug as\n","Naive Bayes, but that doesn’t assume feature independence is the Support\n","Vector Machine (SVM) classifier.\n","\n","You can find more details about SVMs in Chapter 7 of Bishop: Pattern Recognition and Machine Learning.\n","Other sources for learning SVM:\n","* http://web.mit.edu/zoya/www/SVM.pdf\n","* http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf\n","* https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/\n","\n","\n","\n","\n","\n","\n","\n","Use the scikit-learn implementation of \n","[SVM](http://scikit-learn.org/stable/modules/svm.html) with the default parameters. (You are not expected to perform any hyperparameter tuning, but feel free to do it if you think it gives you good insights for the discussion in question 5.)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0LnzNtQBV8gr"},"source":["#### (Q3.1): Train SVM and compare to Naive Bayes (2pts)\n","\n","Train an SVM classifier (sklearn.svm.LinearSVC) using the features collected for Naive Bayes. Compare the\n","classification performance of the SVM classifier to that of the Naive\n","Bayes classifier with smoothing.\n","Use cross-validation to evaluate the performance of the classifiers.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92606,"status":"ok","timestamp":1668517682906,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"JBscui8Mvoz0","outputId":"bc263656-44d2-473f-e03e-24726bd0deef"},"outputs":[{"name":"stdout","output_type":"stream","text":["The accuracy of the SVM is : 0.83\n","Model accuracy ( fold 0 ) : 0.76\n","Model accuracy ( fold 1 ) : 0.85\n","Model accuracy ( fold 2 ) : 0.88\n","Model accuracy ( fold 3 ) : 0.86\n","Model accuracy ( fold 4 ) : 0.87\n","Model accuracy ( fold 5 ) : 0.80\n","Model accuracy ( fold 6 ) : 0.82\n","Model accuracy ( fold 7 ) : 0.89\n","Model accuracy ( fold 8 ) : 0.82\n","Model accuracy ( fold 9 ) : 0.83\n","The mean of the 10 accuracy scores is 0.84 and the variance is 0.00071\n"]}],"source":["# YOUR CODE HERE\n","from sklearn import svm\n","from sklearn.svm import LinearSVC\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split, cross_val_score\n","import scipy\n","from scipy import sparse\n","import pandas as pd\n","\n","def feature_extraction(documents,POS):\n","    \"\"\"\n","    This function creates the feature vector for the SVM. \n","    The data are read and the count of every word for each document is saved. \n","    Then, the labels are put into a numpy vector. 1 for positive and 0 for negative.\n","    The feature vector returned is a docs X words matrix containing the count for each word in each document\n","    and 0 if the word doesn't exist\n","    Args:\n","      documents: the reviews to be taken into consideration for the creation of the features vectors\n","      POS: Flag to determine if we need to take pos_tags into accoutn as well\n","    Returns:\n","      x_vect, y: feature vector, labels\n","    \"\"\"\n","\n","    data = {'pos':[], 'neg':[]}\n","\n","    for review in documents:\n","        bag = {}\n","        for sentence in review[\"content\"]:\n","            for token, pos_tag in sentence:\n","                token = token.lower()\n","                if POS:\n","                    token = token + '_' + pos_tag\n","                if token in bag.keys():\n","                    bag[token] += 1\n","                else:\n","                    bag[token] = 1\n","        if review['sentiment'] == 'POS':\n","            data['pos'].append(bag)\n","        else:\n","            data['neg'].append(bag)\n","\n","    one = np.ones(len(data['pos']))\n","    zero = np.zeros(len(data['neg']))\n","    y = np.concatenate((one,zero))\n","    len_docs = len(y)\n","\n","    v = compute_vocab(data)\n","    len_v = len(v)\n","\n","    x_vect = np.zeros((len_docs, len_v))\n","\n","    data_l = data['neg'] + data['pos']\n","\n","    #build feature vector\n","    for i in range(len_docs):\n","        for j, word in enumerate(v):\n","            if word in data_l[i].keys():\n","                x_vect[i][j] = data_l[i][word]\n","\n","    return x_vect,y\n","\n","    \n","X,Y = feature_extraction(reviews,False)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=42)\n","\n","clf = LinearSVC(max_iter=10000)\n","clf.fit(X_train,y_train)\n","\n","print('The accuracy of the SVM is : %0.2f' %clf.score(X_test,y_test))\n","\n","cvaccuracy = cross_val_score(clf, X_train, y_train, cv=10)\n","for i in range(len(cvaccuracy)):\n","    print('Model accuracy ( fold',i+1,') : %0.2f' %cvaccuracy[i])\n","meanacc = get_mean(cvaccuracy)\n","varacc = get_variance(accuracies)\n","print(\"The mean of the 10 accuracy scores is %0.2f\" %meanacc ,\"and the variance is %0.5f\" %varacc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"elapsed":514,"status":"error","timestamp":1668525841046,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"Mi4UZgVf3aZm","outputId":"4f8d1ff4-4242-4336-c67d-5d638f107072"},"outputs":[],"source":["# YOUR CODE HERE\n","k=10\n","\n","def rrsplit_svm(reviews, k=10):\n","\n","    folds = [ {'pos':[], 'neg':[]} for index in range(k) ]\n","\n","    vocab_size = []\n","    accuracies = []\n","    for i in range(len(data['pos'])):\n","        idx = i % k\n","        folds[idx]['pos'].append(data['pos'][i])\n","        folds[idx]['neg'].append(data['neg'][i])\n","\n","\n","    for i in range(k):\n","        testset = folds[i]\n","        trainset = {'pos':[], 'neg':[]}\n","        for j in range(k):\n","            if i != j:\n","                trainset['pos'] += folds[j]['pos']\n","                trainset['neg'] += folds[j]['neg']\n","        \n","\n","\n","        X_train,Y_train = feature_extraction(trainset,False)\n","        X_test, Y_test = feature_extraction(testset,False)\n","    \n","        clf = LinearSVC(max_iter=10000)\n","        clf.fit(X_train,X_train)\n","        cvaccuracy = cross_val_score(clf, X_test, Y_test, cv=10)\n","        print(cvaccuracy)\n","\n","        \n","    # print(\"Mean Accuracy: %0.2f\" % sum(accuracies) / k)\n","    \n","rrsplit_svm(reviews)\n"]},{"cell_type":"markdown","metadata":{"id":"ifXVWcK0V9qY"},"source":["### POS disambiguation (2pts)\n","\n","Now add in part-of-speech features. You will find the\n","movie review dataset has already been POS-tagged for you ([here](https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf) you find the tagset). Try to\n","replicate the results obtained by Pang et al. (2002).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xA3I82o4oWGu"},"source":["####(Q3.2) Replace your features with word+POS features, and report performance with the SVM. Use cross-validation to evaluate the classifier and compare the results with (Q3.1). Does part-of-speech information help? Explain why this may be the case. (1pt)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92690,"status":"ok","timestamp":1668517775590,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"NOvjYe-t2Br6","outputId":"01faf073-ff66-448f-afc2-c94d77e9fd27"},"outputs":[{"name":"stdout","output_type":"stream","text":["The accuracy of the SVM is : 0.83\n","Model accuracy ( fold 0 ) : 0.79\n","Model accuracy ( fold 1 ) : 0.83\n","Model accuracy ( fold 2 ) : 0.88\n","Model accuracy ( fold 3 ) : 0.85\n","Model accuracy ( fold 4 ) : 0.84\n","Model accuracy ( fold 5 ) : 0.79\n","Model accuracy ( fold 6 ) : 0.84\n","Model accuracy ( fold 7 ) : 0.91\n","Model accuracy ( fold 8 ) : 0.79\n","Model accuracy ( fold 9 ) : 0.86\n","The mean of the 10 accuracy scores is 0.84 and the variance is 0.00139\n"]}],"source":["# YOUR CODE HERE\n","\n","# def feature_extraction(documents,POS):\n","\n","#     y = np.empty(len(documents))\n","\n","#     for i,d in enumerate(documents):\n","#         if documents[i]['sentiment'] == 'POS':\n","#             y[i] = 1\n","#         elif documents[i]['sentiment'] == 'NEG':\n","#             y[i] = 0\n","\n","#     cv = CountVectorizer(lowercase=False)\n","\n","#     revs = pd.DataFrame(documents)\n","#     revs['content'] = revs['content'].apply(clean_text,pos=POS)\n","#     x = revs[['content']]\n","#     x_vect = cv.fit_transform(x['content'])\n","\n","#     return x_vect,y\n","    \n","X,Y = feature_extraction(reviews,True)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=42)\n","\n","clf = LinearSVC(max_iter=10000)\n","clf.fit(X_train,y_train)\n","\n","print('The accuracy of the SVM is : %0.2f' %clf.score(X_test,y_test))\n","\n","cvaccuracypos = cross_val_score(clf, X_train, y_train, cv=10)\n","for i in range(len(cvaccuracypos)):\n","    print('Model accuracy ( fold',i+1,') : %0.2f' %cvaccuracypos[i])\n","meanaccpos = get_mean(cvaccuracypos)\n","varaccpos = get_variance(cvaccuracypos)\n","print(\"The mean of the 10 accuracy scores is %0.2f\" %meanaccpos ,\"and the variance is %0.5f\" %varaccpos)"]},{"cell_type":"markdown","metadata":{"id":"L0dt_oQupUNe"},"source":["*Write your answer here.*\n","\n","As we can see from the cross validation, the average accuracy is only 1% higher when we take into consideration the pos tags. Since the difference is relatively non-existent, we might as well prefer the first case where we do not use the pos tags, as long as they do not contribute to our model reaching a much higher accuracy, while making the whole process more computationally expensive by adding more commands."]},{"cell_type":"markdown","metadata":{"id":"Su-3w87eMW0w"},"source":["#### (Q3.3) Discard all closed-class words from your data (keep only nouns, verbs, adjectives, and adverbs), and report performance. Does this help? Use cross-validation to evaluate the classifier and compare the results with (Q3.2). Are closed-class words detrimental to the classifier? Explain why this may be the case. (1pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67281,"status":"ok","timestamp":1668517842864,"user":{"displayName":"Nikos Apostolikas","userId":"10906912982531458908"},"user_tz":-60},"id":"CCUPlPozCYUX","outputId":"b3f8f9fb-0a12-4efa-9bd3-0713064e147c"},"outputs":[{"name":"stdout","output_type":"stream","text":["The accuracy of the SVM is : 0.82\n","Model accuracy ( fold 0 ) : 0.86\n","Model accuracy ( fold 1 ) : 0.84\n","Model accuracy ( fold 2 ) : 0.81\n","Model accuracy ( fold 3 ) : 0.83\n","Model accuracy ( fold 4 ) : 0.87\n","Model accuracy ( fold 5 ) : 0.85\n","Model accuracy ( fold 6 ) : 0.85\n","Model accuracy ( fold 7 ) : 0.90\n","Model accuracy ( fold 8 ) : 0.84\n","Model accuracy ( fold 9 ) : 0.83\n","The mean of the 10 accuracy scores is 0.85 and the variance is 0.00053\n"]}],"source":["# YOUR CODE HERE\n","\n","def open_feature_extraction(documents):\n","    \"\"\"\n","    Works the same way as feature_extraction, but throws away every token that is a closed-class word\n","    Args:\n","      documents: the reviews to be taken into consideration for the creation of the features vectors\n","    Returns:\n","      x_vect, y: feature vector, labels\n","    \"\"\"\n","    \n","    data = {'pos':[], 'neg':[]}\n","\n","    for review in documents:\n","        bag = {}\n","        for sentence in review[\"content\"]:\n","            for token, pos_tag in sentence:\n","                #Only keep open-class words \n","                if pos_tag.startswith('NN') or pos_tag.startswith('VB') or pos_tag.startswith('JJ') or pos_tag.startswith('RB'):\n","                    token = token.lower() + '_' + pos_tag\n","                    \n","                    if token in bag.keys():\n","                        bag[token] += 1\n","                    else:\n","                        bag[token] = 1\n","        if review['sentiment'] == 'POS':\n","            data['pos'].append(bag)\n","        else:\n","            data['neg'].append(bag)\n","\n","    one = np.ones(len(data['pos']))\n","    zero = np.zeros(len(data['neg']))\n","    y = np.concatenate((one,zero))\n","    len_docs = len(y)\n","\n","    v = compute_vocab(data)\n","    len_v = len(v)\n","\n","    x_vect = np.zeros((len_docs, len_v))\n","\n","    data_l = data['neg'] + data['pos']\n","\n","    #build feature vector\n","    for i in range(len_docs):\n","        for j, word in enumerate(v):\n","            if word in data_l[i].keys():\n","                x_vect[i][j] = data_l[i][word]\n","\n","    # print(x_vect.shape)\n","    # print(y.shape)\n","\n","    return x_vect,y\n","\n","    \n","X,Y = open_feature_extraction(reviews)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state=52)\n","\n","clf = LinearSVC(max_iter=10000)\n","clf.fit(X_train,y_train)\n","\n","print('The accuracy of the SVM is : %0.2f' %clf.score(X_test,y_test))\n","\n","cvaccuracy_openclass = cross_val_score(clf, X_train, y_train, cv=10)\n","for i in range(len(cvaccuracy_openclass)):\n","    print('Model accuracy ( fold',i+1,') : %0.2f' %cvaccuracy_openclass[i])\n","meanacc_openpos = get_mean(cvaccuracy_openclass)\n","varacc_openpos = get_variance(cvaccuracy_openclass)\n","print(\"The mean of the 10 accuracy scores is %0.2f\" %meanacc_openpos ,\"and the variance is %0.5f\" %varacc_openpos)"]},{"cell_type":"markdown","metadata":{"id":"YaxCVrs8pWSp"},"source":["*Write your answer here.*\n","\n","The accuracy of this case where we discard closed-class words is approximately the same as in the question above. This means that the open-class words are more beneficial for our model's training and make it able to reach an acceptable accuracy. This was expected, because if we assume a review contains the verb \"like\" many times, which is an open-class word, then it reveals the reviewer's positive feelings for the movie. Since these words are the ones who matter the most, we can discard the closed-class words."]},{"cell_type":"markdown","metadata":{"id":"nfwqOciAl2No"},"source":["# (Q4) Discussion (max. 500 words). (5pts)\n","\n","> Based on your experiments, what are the effective features and techniques in sentiment analysis? What information do different features encode?\n","Why is this important? What are the limitations of these features and techniques?\n"," \n"]},{"cell_type":"markdown","metadata":{"id":"ZYuse5WLmekZ"},"source":["In this notebook, several approaches were followed in order to classify movie reviews.\n","\n","To begin with, we implemented a lexicon approach, where according to the polarity of the words of the review's content, we made a decision about the review. After incorporating the magnitude of the words, we managed to increase the accuracy from 0.68 to 0.70. This was a very simple approach, so the results taken were expected to not be great.\n","\n","Our next approach was the implementation of the Naive Bayes classifier. The model performed better than the lexicon approach, reaching up to 0.83 accuracy on the given test set. After that, we followed several techniques such as smoothing to \"give\" some extra probability to unseen words. This allowed us to not throw them away, giving us more data to work with. We also used stemming to simplify the vocabulary, but the unstemmed approach performed marginally better. Furthermore, we implemented the n-gram models to test their accuracies. However, even the aforementioned models are not able to deal with long-distance dependencies that might occur in the reviews and that poses a limit to the model's ability to reach even higher accuracy. In addition to that, when we are using the uni+bi+trigram model, then the vocabulary becomes massive. In cases where the vocabulary is small this won't have any major effect, but in other cases the curse dimensionality problem comes up.\n","\n","\n","The final implementation included a SVM to classify the reviews. The SVM performed better than the NB classifier, but the difference was not significant. However, after introducing POS-tags, we observed a minor improvement in accuracy. This makes sense, since we had more features to work with. The next step was about keeping only open-class words, because these are the ones that express the real feelings of the reviewer about the movie. This made our model perform a little bit better, reaching up to 0.85, which was the highest of all our approaches. \n","\n","\n","Nevertheless, it has to be mentioned that the input of the SVM was a matrix of shape (len(reviews),len(vocabulary)), which in some other cases can be massive. Having to deal with such dimensionalities can be very computationally expensive, which poses some limits to the SVM. That's why sparse matrices have to be used to compress the information of the matrix, as it was used in our implementation.\n"]},{"cell_type":"markdown","metadata":{"id":"iwaKwfWQhRk_"},"source":["# Submission \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOUeaET5ijk-"},"outputs":[],"source":["# Write your names and student numbers here:\n","# Nick Apostolikas #14343231\n","# Orestis Gorgogiannis #14480778"]},{"cell_type":"markdown","metadata":{"id":"3A9K-H6Tii3X"},"source":["**That's it!**\n","\n","- Check if you answered all questions fully and correctly. \n","- Download your completed notebook using `File -> Download .ipynb` \n","- Check if your answers are all included in the file you submit.\n","- Submit your .ipynb file via *Canvas*. One submission per group. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHslatYAKBrF"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.3 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.3"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
